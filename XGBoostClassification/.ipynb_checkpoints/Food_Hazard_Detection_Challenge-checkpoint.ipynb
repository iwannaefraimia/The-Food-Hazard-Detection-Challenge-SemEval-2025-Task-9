{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Food Hazard Detection Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a multi-label classification as discribed in the SemEval 2025 Task 9: The Food Hazard Detection Challenge.  \n",
    "The goal is to predict hazard and product categories, as well as specific hazards and products, based on food recall titles and descriptions. The model uses the XGBoost classifier combined with TF-IDF vectorization to extract features from the text column and classify them into the appropriate categories.  \n",
    "The sub-Tasks are:  \n",
    "ST1: Predict hazard category and product category.  \n",
    "ST2: Predict hazard and product.   \n",
    "Specifically, what I do is:  \n",
    "Load and preprocess the data.  \n",
    "Check data quality (missing values, duplicates).  \n",
    "Apply feature extraction using TF-IDF vectorization.   \n",
    "Train multiple XGBoost classifiers for multi-label classification (The training process took about 5 hours to run in my local server).  \n",
    "Evaluate model performance using F1 scores.  \n",
    "Save predictions to submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QpG6yfY5kOn",
    "outputId": "1948b79e-20f4-4006-b661-7c3e8eda77ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in c:\\users\\joann\\appdata\\roaming\\python\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\joann\\appdata\\roaming\\python\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\joann\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn==1.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\joann\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn==1.3.2) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\joann\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\joann\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn==1.3.2) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\joann\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\joann\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\joann\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\joann\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.3.2 xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preparing the data:  \n",
    "I load the labeled training, testing and validation datasets from \"The Food Hazard Detection Challenge\". The datasets contain food-related incidents, including a text column, title, description and their corresponding categories.  \n",
    "I checked for missing and duplicates values to be sure that I am using clean data for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0giBgOAEaHCD",
    "outputId": "761a0411-023a-4118-f3cb-313a3ac14a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Data ---\n",
      "Shape: (5082, 11)\n",
      "Missing values:\n",
      "Unnamed: 0          0\n",
      "year                0\n",
      "month               0\n",
      "day                 0\n",
      "country             0\n",
      "title               0\n",
      "text                0\n",
      "hazard-category     0\n",
      "product-category    0\n",
      "hazard              0\n",
      "product             0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "==================================================\n",
      "--- Testing Data ---\n",
      "Shape: (997, 11)\n",
      "Missing values:\n",
      "Unnamed: 0          0\n",
      "year                0\n",
      "month               0\n",
      "day                 0\n",
      "country             0\n",
      "title               0\n",
      "text                0\n",
      "hazard-category     0\n",
      "product-category    0\n",
      "hazard              0\n",
      "product             0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "==================================================\n",
      "--- Validation Data ---\n",
      "Shape: (565, 11)\n",
      "Missing values:\n",
      "Unnamed: 0          0\n",
      "year                0\n",
      "month               0\n",
      "day                 0\n",
      "country             0\n",
      "title               0\n",
      "text                0\n",
      "hazard-category     0\n",
      "product-category    0\n",
      "hazard              0\n",
      "product             0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load train and test(valid) datasets\n",
    "train_data = pd.read_csv(\"incidents_train.csv\")\n",
    "test_data = pd.read_csv(\"incidents_test.csv\")\n",
    "valid_data = pd.read_csv(\"incidents_valid.csv\")\n",
    "\n",
    "# Checking for missing or duplicate values\n",
    "def check_data_quality(data, name):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(f\"Missing values:\\n{data.isnull().sum()}\\n\")\n",
    "    print(f\"Duplicate rows: {data.duplicated().sum()}\\n\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "check_data_quality(train_data, \"Training Data\")\n",
    "check_data_quality(test_data, \"Testing Data\")\n",
    "check_data_quality(valid_data, \"Validation Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see no missing or dublicate values appear so we can continue to the main part of the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBPYmTCSaztF"
   },
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding:  \n",
    "Since the model only processes numerical inputs:  \n",
    "I encode categorical labels using LabelEncoder for hazard categories, product categories, hazards, and products.  \n",
    "I handle unseen labels in testing and validation data to avoid errors during inference. The transform_with_unknown function makes sure that if some labels not appear in the training set are still represented (using -1 as a placeholder during encoding), so each validation example still gets a prediction from the model. More specifically instead of skipping these examples (which would reduce the number of rows in the results (submission file)), the function assigns a fallback value for unseen labels.  \n",
    "\n",
    "TF-IDF vectorization:  \n",
    "After the encoding I used to convert text into numerical features. This method converts text into numerical form using character-level n-grams (bi-grams to 5-grams). This helps us capture important patterns in textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XfHEHC46afkl"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "X_train = train_data['text']\n",
    "X_test = test_data['text']\n",
    "X_valid = valid_data['text']\n",
    "\n",
    "hazard_category_encoder = LabelEncoder()\n",
    "product_category_encoder = LabelEncoder()\n",
    "hazard_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()\n",
    "\n",
    "# Fitting LabelEncoders on the training data\n",
    "hazard_category_encoder.fit(train_data['hazard-category'])\n",
    "product_category_encoder.fit(train_data['product-category'])\n",
    "hazard_encoder.fit(train_data['hazard'])\n",
    "product_encoder.fit(train_data['product'])\n",
    "\n",
    "# Encoding the training data\n",
    "y_hazard_category = hazard_category_encoder.transform(train_data['hazard-category'])\n",
    "y_product_category = product_category_encoder.transform(train_data['product-category'])\n",
    "y_hazard = hazard_encoder.transform(train_data['hazard'])\n",
    "y_product = product_encoder.transform(train_data['product'])\n",
    "\n",
    "# Handle the unseen labels in the testing, validation data\n",
    "def transform_with_unknown(encoder, labels, fallback_value=-1):\n",
    "    known_labels = encoder.classes_ # checking which labels are present in the encoder\n",
    "    transformed_labels = []\n",
    "    for label in labels:\n",
    "        if label in known_labels:\n",
    "            transformed_labels.append(encoder.transform([label])[0])\n",
    "        else:\n",
    "            transformed_labels.append(fallback_value) \n",
    "\n",
    "    return np.array(transformed_labels)\n",
    "# Encode test labels by using the transform_with_unknown function for unseen labels\n",
    "y_test_hazard_category = transform_with_unknown(hazard_category_encoder, test_data['hazard-category'])\n",
    "y_test_product_category = transform_with_unknown(product_category_encoder, test_data['product-category'])\n",
    "y_test_hazard = transform_with_unknown(hazard_encoder, test_data['hazard'])\n",
    "y_test_product = transform_with_unknown(product_encoder, test_data['product'])\n",
    "\n",
    "# Encode validation labels by using the transform_with_unknown function for unseen labels\n",
    "y_valid_hazard_category = transform_with_unknown(hazard_category_encoder, valid_data['hazard-category'])\n",
    "y_valid_product_category = transform_with_unknown(product_category_encoder, valid_data['product-category'])\n",
    "y_valid_hazard = transform_with_unknown(hazard_encoder, valid_data['hazard'])\n",
    "y_valid_product = transform_with_unknown(product_encoder, valid_data['product'])\n",
    "\n",
    "# Applying Tf-Idf Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, strip_accents='unicode', analyzer='char', ngram_range=(2, 5))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "X_valid_vec = vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training:  \n",
    "Each classifier is trained on the TF-IDF vectorized text data. For the training I used XGBoost Classifiers for each task:  \n",
    "ST1: Hazard Category Prediction  \n",
    "ST1: Product Category Prediction  \n",
    "ST2: Hazard Prediction  \n",
    "ST2: Product Prediction  \n",
    "XGBoost (Extreme Gradient Boosting) is a powerful machine learning algorithm that is widely used for structured data and classification tasks. \n",
    "It was chosen for this task over many other models that I tried, such as K-Nearest-Neighbor, Random-Forest, MultinomialNB, Hist-Gradient-Boosting, SVM, Log-Regression because of:  \n",
    "\n",
    "Handling imbalanced data:  \n",
    "XGBoost includes built-in handling for imbalanced datasets through techniques like scale_pos_weight and boosting iterations, making it suitable for classification tasks where some categories may appear less frequently.\n",
    "\n",
    "High predictive performance:  \n",
    "Compared to other classifiers such as Logistic Regression or traditional Decision Trees, XGBoost typically delivers higher accuracy and better generalization due to its ensemble learning approach.\n",
    "\n",
    "Regularization and pruning:  \n",
    "Unlike simple decision trees, XGBoost applies L1 and L2 regularization, preventing overfitting. It also uses a pruning strategy to remove splits that do not improve performance.\n",
    "\n",
    "Handling Sparse Features:  \n",
    "Since we are using TF-IDF vectorization, which results in a sparse representation of text, XGBoost efficiently handles this type of input, unlike some classifiers that struggle with sparse data.\n",
    "\n",
    "In comparison with other methods like SVM (Support Vector Machines) and Random Forest, which I mentioned before XGBoost was preferred because:\n",
    "SVMs can be computationally expensive when working with large datasets.  \n",
    "Random Forest does not perform as well on high-dimensional text data compared to boosting methods.   \n",
    "\n",
    "All in all, I choose XGBoost, as it balances between efficiency, interpretability, and predictive performance. It also works well for this classification task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "OyeeNmCybS9M",
    "outputId": "bf01f8b2-5f9d-4100-e956-6105415fd365"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ST1: Training model for hazard categorie\n",
    "hazard_category_model_2 = XGBClassifier(random_state=42, eval_metric='mlogloss',n_jobs=-1)\n",
    "hazard_category_model_2.fit(X_train_vec, y_hazard_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "OwB51kkjmYCM",
    "outputId": "fac24cf6-765e-41b3-8412-cb8e12bafc8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ST1: Training model for product categorie\n",
    "product_category_model_2 = XGBClassifier(random_state=42,eval_metric='mlogloss',n_jobs=-1)\n",
    "product_category_model_2.fit(X_train_vec, y_product_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "JE39WM01dabM",
    "outputId": "cd5550b1-90e6-495f-c594-0423a96591cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ST2: Training model for hazard\n",
    "hazard_model_2 = XGBClassifier(random_state=42, eval_metric='mlogloss',n_jobs=-1)\n",
    "hazard_model_2.fit(X_train_vec, y_hazard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "nX9Bz5vI02_c",
    "outputId": "536a8239-f803-4058-d587-32c60a150fb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ST2: Training model for product\n",
    "product_model_2 = XGBClassifier(random_state=42, eval_metric='mlogloss', n_jobs=-1)\n",
    "product_model_2.fit(X_train_vec, y_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the training set for ST1\n",
    "hazard_category_train_preds = hazard_category_model_2.predict(X_train_vec)\n",
    "product_category_train_preds = product_category_model_2.predict(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the training set for ST2\n",
    "hazard_train_preds = hazard_model_2.predict(X_train_vec)\n",
    "product_train_preds = product_model_2.predict(X_train_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, the models make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set for ST1\n",
    "hazard_category_test_preds = hazard_category_model_2.predict(X_test_vec)\n",
    "product_category_test_preds = product_category_model_2.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set for ST2\n",
    "hazard_test_preds = hazard_model_2.predict(X_test_vec)\n",
    "product_test_preds = product_model_2.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnvUn3mSt0sB"
   },
   "source": [
    "# Predictions on Validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, the models make predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qCkCXHbDdylC"
   },
   "outputs": [],
   "source": [
    "# Predictions on the validation set for ST1\n",
    "hazard_category_valid_preds = hazard_category_model_2.predict(X_valid_vec)\n",
    "product_category_valid_preds = product_category_model_2.predict(X_valid_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tjR87tfJd3pW"
   },
   "outputs": [],
   "source": [
    "# Predictions on the validation set for ST2\n",
    "hazard_valid_preds = hazard_model_2.predict(X_valid_vec)\n",
    "product_valid_preds = product_model_2.predict(X_valid_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDJHzvCHeFC-"
   },
   "source": [
    "# Evaluation on Test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use F1 scores to evaluate the performance of the model. The F1 score is a metric that shows how many predicted positive instances are actually correct and how many actual positive instances were correctly predicted.  \n",
    "\n",
    "We have two types of F1 scores:  \n",
    "Macro F1: This calculates the F1 score for each class separately and then averages them, giving equal weight to all classes. This is useful when dealing with imbalanced datasets, as it ensures that small classes are not ignored.  \n",
    "Micro F1: This aggregates predictions across all classes and computes the F1 score based on the overall precision and recall. This favors more frequent classes, meaning it is higher when the model performs well on the dominant categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazard Category - Macro F1: 0.71, Micro F1: 0.93\n",
      "Product Category - Macro F1: 0.50, Micro F1: 0.64\n",
      "Hazard - Macro F1: 0.41, Micro F1: 0.77\n",
      "Product - Macro F1: 0.17, Micro F1: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function to print macro and micro F1 scores\n",
    "def print_f1_scores(y_true, y_pred, label):\n",
    "    macro = f1_score(y_true, y_pred, average='macro')\n",
    "    micro = f1_score(y_true, y_pred, average='micro')\n",
    "    print(f\"{label} - Macro F1: {macro:.2f}, Micro F1: {micro:.2f}\")\n",
    "\n",
    "print_f1_scores(y_test_hazard_category, hazard_category_test_preds, \"Hazard Category\")\n",
    "\n",
    "print_f1_scores(y_test_product_category, product_category_test_preds, \"Product Category\")\n",
    "\n",
    "print_f1_scores(y_test_hazard, hazard_test_preds, \"Hazard\")\n",
    "\n",
    "print_f1_scores(y_test_product, product_test_preds, \"Product\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score Sub-Task 1: 0.605\n",
      "Score Sub-Task 2: 0.298\n"
     ]
    }
   ],
   "source": [
    "# Final Scores on Testing data\n",
    "def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
    "    # Compute F1 for hazards:\n",
    "    f1_hazards = f1_score(\n",
    "        hazards_true,\n",
    "        hazards_pred,\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    # Compute F1 for products:\n",
    "    f1_products = f1_score(\n",
    "        products_true[hazards_pred == hazards_true],\n",
    "        products_pred[hazards_pred == hazards_true],\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    return (f1_hazards + f1_products) / 2.0\n",
    "\n",
    "# Final Score for ST1\n",
    "st1_score = (f1_score(y_test_hazard_category, hazard_category_test_preds, average='macro') +\n",
    "             f1_score(y_test_product_category, product_category_test_preds, average='macro')) / 2.0\n",
    "print(f\"\\nScore Sub-Task 1: {st1_score:.3f}\")\n",
    "\n",
    "# Final Score for ST2\n",
    "st2_score = compute_score(y_test_hazard, y_test_product, hazard_test_preds, product_test_preds)\n",
    "print(f\"Score Sub-Task 2: {st2_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing again the evaluation with F1 scores (Macro and Micro) but now on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "iGKDAMVMeL1J",
    "outputId": "d67bf6ce-5b54-4335-f736-76b7496b2e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazard Category - Macro F1: 0.71, Micro F1: 0.92\n",
      "Product Category - Macro F1: 0.49, Micro F1: 0.61\n",
      "Hazard - Macro F1: 0.44, Micro F1: 0.78\n",
      "Product - Macro F1: 0.17, Micro F1: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function to print macro and micro F1 scores\n",
    "def print_f1_scores(y_true, y_pred, label):\n",
    "    macro = f1_score(y_true, y_pred, average='macro')\n",
    "    micro = f1_score(y_true, y_pred, average='micro')\n",
    "    print(f\"{label} - Macro F1: {macro:.2f}, Micro F1: {micro:.2f}\")\n",
    "\n",
    "print_f1_scores(y_valid_hazard_category, hazard_category_valid_preds, \"Hazard Category\")\n",
    "\n",
    "print_f1_scores(y_valid_product_category, product_category_valid_preds, \"Product Category\")\n",
    "\n",
    "print_f1_scores(y_valid_hazard, hazard_valid_preds, \"Hazard\")\n",
    "\n",
    "print_f1_scores(y_valid_product, product_valid_preds, \"Product\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining the results:  \n",
    "\n",
    "Hazard Category Classification:  \n",
    "Macro F1: 0.71 → The model is performing well across all categories on average, meaning it balances precision and recall effectively. Some classes might be performing better than others, but overall, the results are good.  \n",
    "Micro F1: 0.92 → The model is making very few mistakes in total across all predictions, meaning it predicts the correct hazard category for most cases. \n",
    "All in all, the model is strong at recognizing hazard categories, with high accuracy overall. However, individual smaller classes might have slightly lower performance.\n",
    "\n",
    "Product Category Classification:  \n",
    "Macro F1: 0.49 → The model struggles more with some product categories, meaning that its performance varies significantly between different classes.  \n",
    "Micro F1: 0.61 → The model still correctly classifies a majority of cases, but compared to hazard category classification, it makes more mistakes overall.  \n",
    "All in all, we can see that the performance for product categories is weaker than the one for hazard categories, suggesting that there is more variability in the product labels or that the text data does not contain as clear distinctions between product categories.\n",
    "\n",
    "Hazard Classification:  \n",
    "Macro F1: 0.44 → The model has difficulty generalizing across all hazard classes, meaning that while it may classify some hazards well, others are much harder to predict correctly.  \n",
    "Micro F1: 0.78 → The model is still making mostly correct predictions overall but is struggling with less frequent hazard types.  \n",
    "Here the classification of hazards is weaker than hazard categories, likely due to a larger number of hazard types with more  difference in the dataset.\n",
    "\n",
    "Product Classification:  \n",
    "Macro F1: 0.17 → The model performs poorly across all product classes, meaning that many product labels are misclassified.  \n",
    "Micro F1: 0.33 → Even for the most common product labels, the model struggles to make correct predictions, leading to a high error rate.  \n",
    "It is obvious that, product classification is the hardest task for the model, possibly because product names are more ambiguous or there is less relevant information in the text to distinguish between them. Additionally, the missing or unseen product labels in the validation set may be an additional problem. Since some product labels did not appear in the training data, the model could not learn to classify them correctly. As I handled unseen labels by assigning a fallback value with the transform_with_unknown function, we ensured that the model made predictions for all samples. However, since the model never encountered these labels during training, it struggled to predict them correctly, contributing to the low F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ljknjvLgeSDR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score Sub-Task 1: 0.598\n",
      "Score Sub-Task 2: 0.308\n"
     ]
    }
   ],
   "source": [
    "# Final Scores on Validation data\n",
    "def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
    "    # Compute F1 for hazards:\n",
    "    f1_hazards = f1_score(\n",
    "        hazards_true,\n",
    "        hazards_pred,\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    # Compute F1 for products:\n",
    "    f1_products = f1_score(\n",
    "        products_true[hazards_pred == hazards_true],\n",
    "        products_pred[hazards_pred == hazards_true],\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    return (f1_hazards + f1_products) / 2.0\n",
    "\n",
    "# Final Score for ST1\n",
    "st1_score = (f1_score(y_valid_hazard_category, hazard_category_valid_preds, average='macro') +\n",
    "             f1_score(y_valid_product_category, product_category_valid_preds, average='macro')) / 2.0\n",
    "print(f\"\\nScore Sub-Task 1: {st1_score:.3f}\")\n",
    "\n",
    "# Final Score for ST2\n",
    "st2_score = compute_score(y_valid_hazard, y_valid_product, hazard_valid_preds, product_valid_preds)\n",
    "print(f\"Score Sub-Task 2: {st2_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the final scores:\n",
    "\n",
    "The final scores are calculated by averaging the macro F1 scores for the respective tasks.  \n",
    "Sub-Task 1 - Hazard Category, Product Category:  \n",
    "Final Score: 0.598  \n",
    "This is the average of the macro F1 scores for hazard category (0.71) and product category (0.49).\n",
    "The score is moderate, meaning the model performs reasonably well in classifying hazard and product categories.  \n",
    "\n",
    "Sub-Task 2 - Hazard, Product:  \n",
    "Final Score: 0.308  \n",
    "This is the average of the macro F1 scores for hazard (0.44) and product (0.17).  \n",
    "The low score suggests that predicting specific hazard and product labels is much more difficult than classifying broader categories. The model struggles to differentiate products effectively.  \n",
    "\n",
    "In conclusion the model performs best in hazard category classification, with a high micro F1 score (0.92), meaning it gets most classifications correct overall.  \n",
    "Performance drops for product category classification, meaning it is harder for the model to distinguish between different products.  \n",
    "The worst performance is seen in product classification, meaning the model struggles to classify specific product names.  \n",
    "The final scores reflect these trends, with hazard categories being easier to classify than individual hazards and products.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrqmvHuYdcBx"
   },
   "source": [
    "# Save submission file (validation data results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the final results into a csv file and create a ZIP archive for submission (downloading in our case). The submission file contains the results only for the validation data and not for the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gfo7jsst6-VA"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "# Decoding the predictions with inverse_transform\n",
    "hazard_category_valid_preds_decoded = hazard_category_encoder.inverse_transform(hazard_category_valid_preds)\n",
    "product_category_valid_preds_decoded = product_category_encoder.inverse_transform(product_category_valid_preds)\n",
    "hazard_valid_preds_decoded = hazard_encoder.inverse_transform(hazard_valid_preds)\n",
    "product_valid_preds_decoded = product_encoder.inverse_transform(product_valid_preds)\n",
    "\n",
    "# Combine all decoded predictions to a DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    \"index\": valid_data.index,  \n",
    "    \"hazard_category\": hazard_category_valid_preds_decoded,  \n",
    "    \"product_category\": product_category_valid_preds_decoded, \n",
    "    \"hazard\": hazard_valid_preds_decoded,  \n",
    "    \"product\": product_valid_preds_decoded  \n",
    "})\n",
    "\n",
    "# Create a zip file containing the 'submission.csv'\n",
    "csv_buffer = io.StringIO()\n",
    "submission_df.to_csv(csv_buffer, index=False)\n",
    "csv_data = csv_buffer.getvalue()\n",
    "\n",
    "with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
    "    zipf.writestr(\"submission.csv\", csv_data)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission csv file contains 566 rows, which means that the validation dataset consists of 566 examples for which we need to make predictiocontains More specificall,y it contains 566 food recall texts, and for each of these texts, we generate four predicted labels.\n",
    "The final competition score (Sub-Task 1: 0.598, Sub-Task 2: 0.308) is computed based on how well our model's predictions match the actual categories in this dataset.  \n",
    "Each row in the submission file corresponds to a single food recall entry, and for each row, the model predicts four values:  \n",
    "Hazard Category  \n",
    "Product Category  \n",
    "Hazard  \n",
    "Product  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
